# ML-KB
Machine Learning Knowledge Base

## Neural Network

* [**From perceptron to DEEP Learning**](https://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks)
* [A Quick Introduction to NN](https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/)
* [Back Propagation](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/backpropagation.html)
* [Back Propagation video](https://www.youtube.com/watch?v=GlcnxUlrtek)
* [**A Beginner's Guide To Understanding Convolutional Neural Networks**](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/) - a very good start point to know Convolutional-Neural-Network
* [**25 must know terms for deep learning**](https://www.analyticsvidhya.com/blog/2017/05/25-must-know-terms-concepts-for-beginners-in-deep-learning/?utm_content=buffer3aa63&utm_medium=social&utm_source=pinterest.com&utm_campaign=buffer)
* [**Architecrure of CNN**](https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/) A wonderful article to introduce the architecure of a CNN.

### not read yet, but should be good material.
* [10 dl architecures must know](https://www.analyticsvidhya.com/blog/2017/08/10-advanced-deep-learning-architectures-data-scientists/) - Introduce "Alex net", "VGG net", "Google Net" etc.
* []() 
	* It seems likely that future architectures will feature very few to no pooling layers.
	* It should be noted that the conventional paradigm of a linear list of layers has recently been challenged, in Google’s Inception architectures and also in current (state of the art) Residual Networks from Microsoft Research Asia. 
	* If you’re feeling a bit of a fatigue in thinking about the architectural decisions, you’ll be pleased to know that in 90% or more of applications you should not have to worry about these. I like to summarize this point as “don’t be a hero”: Instead of rolling your own architecture for a problem, you should look at whatever architecture currently works best on ImageNet, download a pretrained model and finetune it on your data. You should rarely ever have to train a ConvNet from scratch or design one from scratch.
	* **some common rules of thumb for sizing the architectures**
	* **Computational Considerations**
	
## Gradient Decent
* [Model Optimization](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/model_optimization.html) - good material about gradient decent.

* [Feature Scaling](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/feature_scaling.htmld)

## TensorFlow
* [Models](https://github.com/tensorflow/models)
* [Keras](https://github.com/keras-team/keras/tree/master/examples)

